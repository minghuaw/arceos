diff --git a/Cargo.lock b/Cargo.lock
index 44fd07c..4a084ef 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -31,6 +31,8 @@ dependencies = [
  "rand",
  "rlsf",
  "slab_allocator",
+ "spin 0.9.8",
+ "talc",
 ]
 
 [[package]]
@@ -471,6 +473,7 @@ dependencies = [
  "axerrno",
  "axfeat",
  "axio",
+ "hashbrown",
  "spinlock",
 ]
 
@@ -1792,6 +1795,15 @@ dependencies = [
  "unicode-ident",
 ]
 
+[[package]]
+name = "talc"
+version = "4.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "104ca9cfd3d275985ac58560d407af681a790d11495f042faaab2af69f63c11a"
+dependencies = [
+ "lock_api",
+]
+
 [[package]]
 name = "thiserror"
 version = "1.0.47"
diff --git a/api/axfeat/Cargo.toml b/api/axfeat/Cargo.toml
index 2947a7e..8c46c22 100644
--- a/api/axfeat/Cargo.toml
+++ b/api/axfeat/Cargo.toml
@@ -26,6 +26,7 @@ alloc = ["axalloc", "axruntime/alloc"]
 alloc-tlsf = ["axalloc/tlsf"]
 alloc-slab = ["axalloc/slab"]
 alloc-buddy = ["axalloc/buddy"]
+alloc-new = ["axalloc/new"]
 paging = ["alloc", "axhal/paging", "axruntime/paging"]
 tls = ["alloc", "axhal/tls", "axruntime/tls", "axtask?/tls"]
 
diff --git a/apps/memtest/src/main.rs b/apps/memtest/src/main.rs
index e23e95e..c05bc5c 100644
--- a/apps/memtest/src/main.rs
+++ b/apps/memtest/src/main.rs
@@ -6,7 +6,7 @@
 extern crate axstd as std;
 
 use rand::{rngs::SmallRng, RngCore, SeedableRng};
-use std::collections::BTreeMap;
+use std::collections::HashMap;
 use std::vec::Vec;
 
 fn test_vec(rng: &mut impl RngCore) {
@@ -22,9 +22,9 @@ fn test_vec(rng: &mut impl RngCore) {
     println!("test_vec() OK!");
 }
 
-fn test_btree_map(rng: &mut impl RngCore) {
+fn test_hashmap_map(rng: &mut impl RngCore) {
     const N: usize = 50_000;
-    let mut m = BTreeMap::new();
+    let mut m = HashMap::new();
     for _ in 0..N {
         let value = rng.next_u32();
         let key = format!("key_{value}");
@@ -35,7 +35,7 @@ fn test_btree_map(rng: &mut impl RngCore) {
             assert_eq!(k.parse::<u32>().unwrap(), *v);
         }
     }
-    println!("test_btree_map() OK!");
+    println!("test_hashmap_map() OK!");
 }
 
 #[cfg_attr(feature = "axstd", no_mangle)]
@@ -44,7 +44,7 @@ fn main() {
 
     let mut rng = SmallRng::seed_from_u64(0xdead_beef);
     test_vec(&mut rng);
-    test_btree_map(&mut rng);
+    test_hashmap_map(&mut rng);
 
     println!("Memory tests run OK!");
 }
diff --git a/crates/allocator/Cargo.toml b/crates/allocator/Cargo.toml
index b8770f1..12c22a6 100644
--- a/crates/allocator/Cargo.toml
+++ b/crates/allocator/Cargo.toml
@@ -11,13 +11,14 @@ documentation = "https://rcore-os.github.io/arceos/allocator/index.html"
 
 [features]
 default = []
-full = ["bitmap", "tlsf", "slab", "buddy", "allocator_api"]
+full = ["bitmap", "tlsf", "slab", "buddy", "new", "allocator_api"]
 
 bitmap = ["dep:bitmap-allocator"]
 
 tlsf = ["dep:rlsf"]
 slab = ["dep:slab_allocator"]
 buddy = ["dep:buddy_system_allocator"]
+new = ["dep:talc", "dep:spin"]
 
 allocator_api = []
 
@@ -26,6 +27,8 @@ buddy_system_allocator = { version = "0.9", default-features = false, optional =
 slab_allocator = { path = "../slab_allocator", optional = true }
 rlsf = { version = "0.2", optional = true }
 bitmap-allocator = { git = "https://github.com/rcore-os/bitmap-allocator.git", rev = "88e871a", optional = true }
+talc = { version = "4", optional = true }
+spin = { version = "0.9", optional = true }
 
 [dev-dependencies]
 allocator = { path = ".", features = ["full"] }
diff --git a/crates/allocator/src/lib.rs b/crates/allocator/src/lib.rs
index 7a79161..59ad417 100644
--- a/crates/allocator/src/lib.rs
+++ b/crates/allocator/src/lib.rs
@@ -31,6 +31,11 @@ mod tlsf;
 #[cfg(feature = "tlsf")]
 pub use tlsf::TlsfByteAllocator;
 
+#[cfg(feature = "new")]
+mod new;
+#[cfg(feature = "new")]
+pub use new::YourNewAllocator;
+
 use core::alloc::Layout;
 use core::ptr::NonNull;
 
diff --git a/crates/allocator/src/new.rs b/crates/allocator/src/new.rs
new file mode 100644
index 0000000..52955ec
--- /dev/null
+++ b/crates/allocator/src/new.rs
@@ -0,0 +1,78 @@
+//! Talc allocation
+
+use crate::{AllocError, AllocResult, BaseAllocator, ByteAllocator};
+
+use talc::{ErrOnOom, Span, Talc, Talck};
+
+pub struct YourNewAllocator {
+    talc: Talck<spin::Mutex<()>, ErrOnOom>,
+    claimed_span: Option<Span>,
+    used_bytes: usize,
+}
+
+impl YourNewAllocator {
+    pub const fn new() -> Self {
+        Self {
+            talc: Talc::new(ErrOnOom).lock::<spin::Mutex<()>>(),
+            claimed_span: None,
+            used_bytes: 0,
+        }
+    }
+}
+
+impl BaseAllocator for YourNewAllocator {
+    fn init(&mut self, start: usize, size: usize) {
+        let span_to_claim = Span::from_base_size(start as *mut u8, size);
+        let span = unsafe {
+             self.talc.lock().claim(span_to_claim).unwrap() // Simply panic if the claim fails
+        };
+        self.claimed_span = Some(span);
+    }
+
+    fn add_memory(&mut self, start: usize, size: usize) -> AllocResult {
+        let span_to_claim = Span::from_base_size(start as *mut u8, size);
+
+        match self.claimed_span {
+            Some(old_heap) => {
+                let req_heap = old_heap.clone().fit_over(span_to_claim);
+                let new_span = unsafe {
+                    self.talc.lock().extend(old_heap, req_heap)
+                };
+                self.claimed_span = Some(new_span);
+                Ok(())
+            },
+            None => {
+                let span = unsafe {
+                    self.talc.lock().claim(span_to_claim).unwrap() // Simply panic if the claim fails
+                };
+                self.claimed_span = Some(span);
+                Ok(())
+            }
+        }
+    }
+}
+
+impl ByteAllocator for YourNewAllocator {
+    fn alloc(&mut self, layout: core::alloc::Layout) -> AllocResult<core::ptr::NonNull<u8>> {
+        let ptr = unsafe { self.talc.lock().malloc(layout).map_err(|_| AllocError::NoMemory) }?;
+        self.used_bytes = self.used_bytes.checked_add(layout.size()).ok_or(AllocError::MemoryOverlap)?;
+        Ok(ptr)
+    }
+
+    fn dealloc(&mut self, pos: core::ptr::NonNull<u8>, layout: core::alloc::Layout) {
+        unsafe { self.talc.lock().free(pos, layout) }
+        self.used_bytes = self.used_bytes.saturating_sub(layout.size());
+    }
+
+    fn total_bytes(&self) -> usize {
+        self.claimed_span.as_ref().map(|s| s.size()).unwrap_or(0)
+    }
+
+    fn used_bytes(&self) -> usize {
+        self.used_bytes
+    }
+
+    fn available_bytes(&self) -> usize {
+        self.total_bytes() - self.used_bytes()
+    }
+}
\ No newline at end of file
diff --git a/minghuaw-lesson1.patch b/minghuaw-lesson1.patch
new file mode 100644
index 0000000..c0d11e3
--- /dev/null
+++ b/minghuaw-lesson1.patch
@@ -0,0 +1,523 @@
+diff --git a/Cargo.lock b/Cargo.lock
+index 44fd07c..4a084ef 100644
+--- a/Cargo.lock
++++ b/Cargo.lock
+@@ -31,6 +31,8 @@ dependencies = [
+  "rand",
+  "rlsf",
+  "slab_allocator",
++ "spin 0.9.8",
++ "talc",
+ ]
+ 
+ [[package]]
+@@ -471,6 +473,7 @@ dependencies = [
+  "axerrno",
+  "axfeat",
+  "axio",
++ "hashbrown",
+  "spinlock",
+ ]
+ 
+@@ -1792,6 +1795,15 @@ dependencies = [
+  "unicode-ident",
+ ]
+ 
++[[package]]
++name = "talc"
++version = "4.2.0"
++source = "registry+https://github.com/rust-lang/crates.io-index"
++checksum = "104ca9cfd3d275985ac58560d407af681a790d11495f042faaab2af69f63c11a"
++dependencies = [
++ "lock_api",
++]
++
+ [[package]]
+ name = "thiserror"
+ version = "1.0.47"
+diff --git a/api/axfeat/Cargo.toml b/api/axfeat/Cargo.toml
+index 2947a7e..8c46c22 100644
+--- a/api/axfeat/Cargo.toml
++++ b/api/axfeat/Cargo.toml
+@@ -26,6 +26,7 @@ alloc = ["axalloc", "axruntime/alloc"]
+ alloc-tlsf = ["axalloc/tlsf"]
+ alloc-slab = ["axalloc/slab"]
+ alloc-buddy = ["axalloc/buddy"]
++alloc-new = ["axalloc/new"]
+ paging = ["alloc", "axhal/paging", "axruntime/paging"]
+ tls = ["alloc", "axhal/tls", "axruntime/tls", "axtask?/tls"]
+ 
+diff --git a/apps/memtest/src/main.rs b/apps/memtest/src/main.rs
+index e23e95e..c05bc5c 100644
+--- a/apps/memtest/src/main.rs
++++ b/apps/memtest/src/main.rs
+@@ -6,7 +6,7 @@
+ extern crate axstd as std;
+ 
+ use rand::{rngs::SmallRng, RngCore, SeedableRng};
+-use std::collections::BTreeMap;
++use std::collections::HashMap;
+ use std::vec::Vec;
+ 
+ fn test_vec(rng: &mut impl RngCore) {
+@@ -22,9 +22,9 @@ fn test_vec(rng: &mut impl RngCore) {
+     println!("test_vec() OK!");
+ }
+ 
+-fn test_btree_map(rng: &mut impl RngCore) {
++fn test_hashmap_map(rng: &mut impl RngCore) {
+     const N: usize = 50_000;
+-    let mut m = BTreeMap::new();
++    let mut m = HashMap::new();
+     for _ in 0..N {
+         let value = rng.next_u32();
+         let key = format!("key_{value}");
+@@ -35,7 +35,7 @@ fn test_btree_map(rng: &mut impl RngCore) {
+             assert_eq!(k.parse::<u32>().unwrap(), *v);
+         }
+     }
+-    println!("test_btree_map() OK!");
++    println!("test_hashmap_map() OK!");
+ }
+ 
+ #[cfg_attr(feature = "axstd", no_mangle)]
+@@ -44,7 +44,7 @@ fn main() {
+ 
+     let mut rng = SmallRng::seed_from_u64(0xdead_beef);
+     test_vec(&mut rng);
+-    test_btree_map(&mut rng);
++    test_hashmap_map(&mut rng);
+ 
+     println!("Memory tests run OK!");
+ }
+diff --git a/crates/allocator/Cargo.toml b/crates/allocator/Cargo.toml
+index b8770f1..12c22a6 100644
+--- a/crates/allocator/Cargo.toml
++++ b/crates/allocator/Cargo.toml
+@@ -11,13 +11,14 @@ documentation = "https://rcore-os.github.io/arceos/allocator/index.html"
+ 
+ [features]
+ default = []
+-full = ["bitmap", "tlsf", "slab", "buddy", "allocator_api"]
++full = ["bitmap", "tlsf", "slab", "buddy", "new", "allocator_api"]
+ 
+ bitmap = ["dep:bitmap-allocator"]
+ 
+ tlsf = ["dep:rlsf"]
+ slab = ["dep:slab_allocator"]
+ buddy = ["dep:buddy_system_allocator"]
++new = ["dep:talc", "dep:spin"]
+ 
+ allocator_api = []
+ 
+@@ -26,6 +27,8 @@ buddy_system_allocator = { version = "0.9", default-features = false, optional =
+ slab_allocator = { path = "../slab_allocator", optional = true }
+ rlsf = { version = "0.2", optional = true }
+ bitmap-allocator = { git = "https://github.com/rcore-os/bitmap-allocator.git", rev = "88e871a", optional = true }
++talc = { version = "4", optional = true }
++spin = { version = "0.9", optional = true }
+ 
+ [dev-dependencies]
+ allocator = { path = ".", features = ["full"] }
+diff --git a/crates/allocator/src/lib.rs b/crates/allocator/src/lib.rs
+index 7a79161..59ad417 100644
+--- a/crates/allocator/src/lib.rs
++++ b/crates/allocator/src/lib.rs
+@@ -31,6 +31,11 @@ mod tlsf;
+ #[cfg(feature = "tlsf")]
+ pub use tlsf::TlsfByteAllocator;
+ 
++#[cfg(feature = "new")]
++mod new;
++#[cfg(feature = "new")]
++pub use new::YourNewAllocator;
++
+ use core::alloc::Layout;
+ use core::ptr::NonNull;
+ 
+diff --git a/crates/allocator/src/new.rs b/crates/allocator/src/new.rs
+new file mode 100644
+index 0000000..52955ec
+--- /dev/null
++++ b/crates/allocator/src/new.rs
+@@ -0,0 +1,78 @@
++//! Talc allocation
++
++use crate::{AllocError, AllocResult, BaseAllocator, ByteAllocator};
++
++use talc::{ErrOnOom, Span, Talc, Talck};
++
++pub struct YourNewAllocator {
++    talc: Talck<spin::Mutex<()>, ErrOnOom>,
++    claimed_span: Option<Span>,
++    used_bytes: usize,
++}
++
++impl YourNewAllocator {
++    pub const fn new() -> Self {
++        Self {
++            talc: Talc::new(ErrOnOom).lock::<spin::Mutex<()>>(),
++            claimed_span: None,
++            used_bytes: 0,
++        }
++    }
++}
++
++impl BaseAllocator for YourNewAllocator {
++    fn init(&mut self, start: usize, size: usize) {
++        let span_to_claim = Span::from_base_size(start as *mut u8, size);
++        let span = unsafe {
++             self.talc.lock().claim(span_to_claim).unwrap() // Simply panic if the claim fails
++        };
++        self.claimed_span = Some(span);
++    }
++
++    fn add_memory(&mut self, start: usize, size: usize) -> AllocResult {
++        let span_to_claim = Span::from_base_size(start as *mut u8, size);
++
++        match self.claimed_span {
++            Some(old_heap) => {
++                let req_heap = old_heap.clone().fit_over(span_to_claim);
++                let new_span = unsafe {
++                    self.talc.lock().extend(old_heap, req_heap)
++                };
++                self.claimed_span = Some(new_span);
++                Ok(())
++            },
++            None => {
++                let span = unsafe {
++                    self.talc.lock().claim(span_to_claim).unwrap() // Simply panic if the claim fails
++                };
++                self.claimed_span = Some(span);
++                Ok(())
++            }
++        }
++    }
++}
++
++impl ByteAllocator for YourNewAllocator {
++    fn alloc(&mut self, layout: core::alloc::Layout) -> AllocResult<core::ptr::NonNull<u8>> {
++        let ptr = unsafe { self.talc.lock().malloc(layout).map_err(|_| AllocError::NoMemory) }?;
++        self.used_bytes = self.used_bytes.checked_add(layout.size()).ok_or(AllocError::MemoryOverlap)?;
++        Ok(ptr)
++    }
++
++    fn dealloc(&mut self, pos: core::ptr::NonNull<u8>, layout: core::alloc::Layout) {
++        unsafe { self.talc.lock().free(pos, layout) }
++        self.used_bytes = self.used_bytes.saturating_sub(layout.size());
++    }
++
++    fn total_bytes(&self) -> usize {
++        self.claimed_span.as_ref().map(|s| s.size()).unwrap_or(0)
++    }
++
++    fn used_bytes(&self) -> usize {
++        self.used_bytes
++    }
++
++    fn available_bytes(&self) -> usize {
++        self.total_bytes() - self.used_bytes()
++    }
++}
+\ No newline at end of file
+diff --git a/modules/axalloc/Cargo.toml b/modules/axalloc/Cargo.toml
+index 40eedf4..63472be 100644
+--- a/modules/axalloc/Cargo.toml
++++ b/modules/axalloc/Cargo.toml
+@@ -14,6 +14,7 @@ default = ["tlsf"]
+ tlsf = ["allocator/tlsf"]
+ slab = ["allocator/slab"]
+ buddy = ["allocator/buddy"]
++new = ["allocator/new"]
+ 
+ [dependencies]
+ log = "0.4"
+diff --git a/modules/axalloc/src/lib.rs b/modules/axalloc/src/lib.rs
+index 096ce95..d6fdf05 100644
+--- a/modules/axalloc/src/lib.rs
++++ b/modules/axalloc/src/lib.rs
+@@ -28,9 +28,11 @@ cfg_if::cfg_if! {
+         use allocator::SlabByteAllocator as DefaultByteAllocator;
+     } else if #[cfg(feature = "buddy")] {
+         use allocator::BuddyByteAllocator as DefaultByteAllocator;
++    } else if #[cfg(feature = "new")] {
++        use allocator::YourNewAllocator as DefaultByteAllocator;
+     } else if #[cfg(feature = "tlsf")] {
+         use allocator::TlsfByteAllocator as DefaultByteAllocator;
+-    }
++    } 
+ }
+ 
+ /// The global allocator used by ArceOS.
+@@ -65,6 +67,8 @@ impl GlobalAllocator {
+                 "slab"
+             } else if #[cfg(feature = "buddy")] {
+                 "buddy"
++            } else if #[cfg(feature = "new")] {
++                "new"
+             } else if #[cfg(feature = "tlsf")] {
+                 "TLSF"
+             }
+diff --git a/ulib/axstd/Cargo.toml b/ulib/axstd/Cargo.toml
+index 83239c3..00b3484 100644
+--- a/ulib/axstd/Cargo.toml
++++ b/ulib/axstd/Cargo.toml
+@@ -33,6 +33,7 @@ alloc = ["arceos_api/alloc", "axfeat/alloc", "axio/alloc"]
+ alloc-tlsf = ["axfeat/alloc-tlsf"]
+ alloc-slab = ["axfeat/alloc-slab"]
+ alloc-buddy = ["axfeat/alloc-buddy"]
++alloc-new = ["axfeat/alloc-new"]
+ paging = ["axfeat/paging"]
+ tls = ["axfeat/tls"]
+ 
+@@ -74,3 +75,5 @@ arceos_api = { path = "../../api/arceos_api" }
+ axio = { path = "../../crates/axio" }
+ axerrno = { path = "../../crates/axerrno" }
+ spinlock = { path = "../../crates/spinlock" }
++
++hashbrown = { version = "0.14", default-features = false }
+\ No newline at end of file
+diff --git a/ulib/axstd/src/collections/hash/map.rs b/ulib/axstd/src/collections/hash/map.rs
+new file mode 100644
+index 0000000..9fbfec7
+--- /dev/null
++++ b/ulib/axstd/src/collections/hash/map.rs
+@@ -0,0 +1,94 @@
++use core::hash::{BuildHasher, Hash};
++use crate::hash::RandomState;
++
++use hashbrown::hash_map as base;
++
++pub struct HashMap<K, V, S = RandomState> {
++    base: base::HashMap<K, V, S>,
++}
++
++impl<K, V> HashMap<K, V, RandomState> {
++    #[inline]
++    #[must_use]
++    pub fn new() -> HashMap<K, V, RandomState> {
++        Default::default()
++    }
++
++    #[inline]
++    #[must_use]
++    pub fn with_capacity(capacity: usize) -> HashMap<K, V, RandomState> {
++        HashMap::with_capacity_and_hasher(capacity, Default::default())
++    }
++}
++
++impl<K, V, S> HashMap<K, V, S> {
++    pub const fn with_hasher(hash_builder: S) -> HashMap<K, V, S> {
++        HashMap { base: base::HashMap::with_hasher(hash_builder) }
++    }
++
++    pub fn with_capacity_and_hasher(capacity: usize, hasher: S) -> HashMap<K, V, S> {
++        HashMap { base: base::HashMap::with_capacity_and_hasher(capacity, hasher) }
++    }
++
++    pub fn iter(&self) -> Iter<'_, K, V> {
++        Iter { base: self.base.iter() }
++    }
++}
++
++impl<K, V, S> HashMap<K, V, S> 
++where
++    K: Eq + Hash,
++    S: BuildHasher,
++{
++    #[inline]
++    pub fn insert(&mut self, k: K, v: V) -> Option<V> {
++        self.base.insert(k, v)
++    }
++}
++
++pub struct Iter<'a, K: 'a, V: 'a> {
++    base: base::Iter<'a, K, V>,
++}
++
++impl<'a, K, V> Iterator for Iter<'a, K, V> {
++    type Item = (&'a K, &'a V);
++
++    #[inline]
++    fn next(&mut self) -> Option<(&'a K, &'a V)> {
++        self.base.next()
++    }
++    #[inline]
++    fn size_hint(&self) -> (usize, Option<usize>) {
++        self.base.size_hint()
++    }
++    #[inline]
++    fn count(self) -> usize {
++        self.base.len()
++    }
++    #[inline]
++    fn fold<B, F>(self, init: B, f: F) -> B
++    where
++        Self: Sized,
++        F: FnMut(B, Self::Item) -> B,
++    {
++        self.base.fold(init, f)
++    }
++}
++
++impl<K, V> ExactSizeIterator for Iter<'_, K, V> {
++    #[inline]
++    fn len(&self) -> usize {
++        self.base.len()
++    }
++}
++
++impl<K, V, S> Default for HashMap<K, V, S>
++where
++    S: Default,
++{
++    /// Creates an empty `HashMap<K, V, S>`, with the `Default` value for the hasher.
++    #[inline]
++    fn default() -> HashMap<K, V, S> {
++        HashMap::with_hasher(Default::default())
++    }
++}
+\ No newline at end of file
+diff --git a/ulib/axstd/src/collections/hash/mod.rs b/ulib/axstd/src/collections/hash/mod.rs
+new file mode 100644
+index 0000000..5022969
+--- /dev/null
++++ b/ulib/axstd/src/collections/hash/mod.rs
+@@ -0,0 +1 @@
++pub(crate) mod map;
+\ No newline at end of file
+diff --git a/ulib/axstd/src/collections/mod.rs b/ulib/axstd/src/collections/mod.rs
+new file mode 100644
+index 0000000..65a93df
+--- /dev/null
++++ b/ulib/axstd/src/collections/mod.rs
+@@ -0,0 +1,4 @@
++pub use ::alloc::collections::*;
++
++mod hash;
++pub use hash::map::HashMap;
+\ No newline at end of file
+diff --git a/ulib/axstd/src/hash/mod.rs b/ulib/axstd/src/hash/mod.rs
+new file mode 100644
+index 0000000..d8f0616
+--- /dev/null
++++ b/ulib/axstd/src/hash/mod.rs
+@@ -0,0 +1,3 @@
++pub(crate) mod random;
++
++pub use random::{DefaultHasher, RandomState};
+\ No newline at end of file
+diff --git a/ulib/axstd/src/hash/random.rs b/ulib/axstd/src/hash/random.rs
+new file mode 100644
+index 0000000..2735c4c
+--- /dev/null
++++ b/ulib/axstd/src/hash/random.rs
+@@ -0,0 +1,75 @@
++#![allow(deprecated)]
++use core::hash::{BuildHasher, Hasher, SipHasher13};
++
++use spinlock::SpinNoIrq;
++
++static PARK_MILLER_LEHMER_SEED: SpinNoIrq<u32> = SpinNoIrq::new(0);
++const RAND_MAX: u64 = 2_147_483_647;
++
++pub fn random() -> u128 {
++    let mut seed = PARK_MILLER_LEHMER_SEED.lock();
++    if *seed == 0 {
++        *seed = arceos_api::time::ax_current_time().as_micros() as u32;
++    }
++
++    let mut ret: u128 = 0;
++    for _ in 0..4 {
++        *seed = ((u64::from(*seed) * 48271) % RAND_MAX) as u32;
++        ret = (ret << 32) | (*seed as u128);
++    }
++    ret
++}
++
++pub struct RandomState {
++    k0: u64,
++    k1: u64,
++}
++
++impl RandomState {
++    pub fn new() -> RandomState {
++        let r = random();
++        RandomState {
++            k0: r as u64,
++            k1: (r >> 64) as u64,
++        }
++    }
++}
++
++pub struct DefaultHasher(SipHasher13);
++
++impl BuildHasher for RandomState {
++    type Hasher = DefaultHasher;
++    #[inline]
++    #[allow(deprecated)]
++    fn build_hasher(&self) -> DefaultHasher {
++        DefaultHasher(SipHasher13::new_with_keys(self.k0, self.k1))
++    }
++}
++
++impl Hasher for DefaultHasher {
++    // The underlying `SipHasher13` doesn't override the other
++    // `write_*` methods, so it's ok not to forward them here.
++
++    #[inline]
++    fn write(&mut self, msg: &[u8]) {
++        self.0.write(msg)
++    }
++
++    #[inline]
++    fn write_str(&mut self, s: &str) {
++        self.0.write_str(s);
++    }
++
++    #[inline]
++    fn finish(&self) -> u64 {
++        self.0.finish()
++    }
++}
++
++impl Default for RandomState {
++    /// Constructs a new `RandomState`.
++    #[inline]
++    fn default() -> RandomState {
++        RandomState::new()
++    }
++}
+diff --git a/ulib/axstd/src/lib.rs b/ulib/axstd/src/lib.rs
+index d256cd5..59de1d3 100644
+--- a/ulib/axstd/src/lib.rs
++++ b/ulib/axstd/src/lib.rs
+@@ -49,13 +49,27 @@
+ #![cfg_attr(all(not(test), not(doc)), no_std)]
+ #![feature(doc_cfg)]
+ #![feature(doc_auto_cfg)]
++#![allow(internal_features)] // suppress warnings for feature hashmap_internals
++#![feature(hashmap_internals)]
++#![feature(extend_one)]
++#![feature(hasher_prefixfree_extras)]
++#![feature(error_in_core)]
++#![feature(try_reserve_kind)]
++#![feature(thread_local)]
++#![feature(const_hash)]
+ 
+ #[cfg(feature = "alloc")]
+ extern crate alloc;
+ 
+ #[cfg(feature = "alloc")]
+ #[doc(no_inline)]
+-pub use alloc::{boxed, collections, format, string, vec};
++pub use alloc::{boxed, format, string, vec};
++
++#[cfg(feature = "alloc")]
++pub mod collections;
++
++#[cfg(feature = "alloc")]
++pub mod hash;
+ 
+ #[doc(no_inline)]
+ pub use core::{arch, cell, cmp, hint, marker, mem, ops, ptr, slice, str};
diff --git a/modules/axalloc/Cargo.toml b/modules/axalloc/Cargo.toml
index 40eedf4..63472be 100644
--- a/modules/axalloc/Cargo.toml
+++ b/modules/axalloc/Cargo.toml
@@ -14,6 +14,7 @@ default = ["tlsf"]
 tlsf = ["allocator/tlsf"]
 slab = ["allocator/slab"]
 buddy = ["allocator/buddy"]
+new = ["allocator/new"]
 
 [dependencies]
 log = "0.4"
diff --git a/modules/axalloc/src/lib.rs b/modules/axalloc/src/lib.rs
index 096ce95..d6fdf05 100644
--- a/modules/axalloc/src/lib.rs
+++ b/modules/axalloc/src/lib.rs
@@ -28,9 +28,11 @@ cfg_if::cfg_if! {
         use allocator::SlabByteAllocator as DefaultByteAllocator;
     } else if #[cfg(feature = "buddy")] {
         use allocator::BuddyByteAllocator as DefaultByteAllocator;
+    } else if #[cfg(feature = "new")] {
+        use allocator::YourNewAllocator as DefaultByteAllocator;
     } else if #[cfg(feature = "tlsf")] {
         use allocator::TlsfByteAllocator as DefaultByteAllocator;
-    }
+    } 
 }
 
 /// The global allocator used by ArceOS.
@@ -65,6 +67,8 @@ impl GlobalAllocator {
                 "slab"
             } else if #[cfg(feature = "buddy")] {
                 "buddy"
+            } else if #[cfg(feature = "new")] {
+                "new"
             } else if #[cfg(feature = "tlsf")] {
                 "TLSF"
             }
diff --git a/ulib/axstd/Cargo.toml b/ulib/axstd/Cargo.toml
index 83239c3..00b3484 100644
--- a/ulib/axstd/Cargo.toml
+++ b/ulib/axstd/Cargo.toml
@@ -33,6 +33,7 @@ alloc = ["arceos_api/alloc", "axfeat/alloc", "axio/alloc"]
 alloc-tlsf = ["axfeat/alloc-tlsf"]
 alloc-slab = ["axfeat/alloc-slab"]
 alloc-buddy = ["axfeat/alloc-buddy"]
+alloc-new = ["axfeat/alloc-new"]
 paging = ["axfeat/paging"]
 tls = ["axfeat/tls"]
 
@@ -74,3 +75,5 @@ arceos_api = { path = "../../api/arceos_api" }
 axio = { path = "../../crates/axio" }
 axerrno = { path = "../../crates/axerrno" }
 spinlock = { path = "../../crates/spinlock" }
+
+hashbrown = { version = "0.14", default-features = false }
\ No newline at end of file
diff --git a/ulib/axstd/src/collections/hash/map.rs b/ulib/axstd/src/collections/hash/map.rs
new file mode 100644
index 0000000..9fbfec7
--- /dev/null
+++ b/ulib/axstd/src/collections/hash/map.rs
@@ -0,0 +1,94 @@
+use core::hash::{BuildHasher, Hash};
+use crate::hash::RandomState;
+
+use hashbrown::hash_map as base;
+
+pub struct HashMap<K, V, S = RandomState> {
+    base: base::HashMap<K, V, S>,
+}
+
+impl<K, V> HashMap<K, V, RandomState> {
+    #[inline]
+    #[must_use]
+    pub fn new() -> HashMap<K, V, RandomState> {
+        Default::default()
+    }
+
+    #[inline]
+    #[must_use]
+    pub fn with_capacity(capacity: usize) -> HashMap<K, V, RandomState> {
+        HashMap::with_capacity_and_hasher(capacity, Default::default())
+    }
+}
+
+impl<K, V, S> HashMap<K, V, S> {
+    pub const fn with_hasher(hash_builder: S) -> HashMap<K, V, S> {
+        HashMap { base: base::HashMap::with_hasher(hash_builder) }
+    }
+
+    pub fn with_capacity_and_hasher(capacity: usize, hasher: S) -> HashMap<K, V, S> {
+        HashMap { base: base::HashMap::with_capacity_and_hasher(capacity, hasher) }
+    }
+
+    pub fn iter(&self) -> Iter<'_, K, V> {
+        Iter { base: self.base.iter() }
+    }
+}
+
+impl<K, V, S> HashMap<K, V, S> 
+where
+    K: Eq + Hash,
+    S: BuildHasher,
+{
+    #[inline]
+    pub fn insert(&mut self, k: K, v: V) -> Option<V> {
+        self.base.insert(k, v)
+    }
+}
+
+pub struct Iter<'a, K: 'a, V: 'a> {
+    base: base::Iter<'a, K, V>,
+}
+
+impl<'a, K, V> Iterator for Iter<'a, K, V> {
+    type Item = (&'a K, &'a V);
+
+    #[inline]
+    fn next(&mut self) -> Option<(&'a K, &'a V)> {
+        self.base.next()
+    }
+    #[inline]
+    fn size_hint(&self) -> (usize, Option<usize>) {
+        self.base.size_hint()
+    }
+    #[inline]
+    fn count(self) -> usize {
+        self.base.len()
+    }
+    #[inline]
+    fn fold<B, F>(self, init: B, f: F) -> B
+    where
+        Self: Sized,
+        F: FnMut(B, Self::Item) -> B,
+    {
+        self.base.fold(init, f)
+    }
+}
+
+impl<K, V> ExactSizeIterator for Iter<'_, K, V> {
+    #[inline]
+    fn len(&self) -> usize {
+        self.base.len()
+    }
+}
+
+impl<K, V, S> Default for HashMap<K, V, S>
+where
+    S: Default,
+{
+    /// Creates an empty `HashMap<K, V, S>`, with the `Default` value for the hasher.
+    #[inline]
+    fn default() -> HashMap<K, V, S> {
+        HashMap::with_hasher(Default::default())
+    }
+}
\ No newline at end of file
diff --git a/ulib/axstd/src/collections/hash/mod.rs b/ulib/axstd/src/collections/hash/mod.rs
new file mode 100644
index 0000000..5022969
--- /dev/null
+++ b/ulib/axstd/src/collections/hash/mod.rs
@@ -0,0 +1 @@
+pub(crate) mod map;
\ No newline at end of file
diff --git a/ulib/axstd/src/collections/mod.rs b/ulib/axstd/src/collections/mod.rs
new file mode 100644
index 0000000..65a93df
--- /dev/null
+++ b/ulib/axstd/src/collections/mod.rs
@@ -0,0 +1,4 @@
+pub use ::alloc::collections::*;
+
+mod hash;
+pub use hash::map::HashMap;
\ No newline at end of file
diff --git a/ulib/axstd/src/hash/mod.rs b/ulib/axstd/src/hash/mod.rs
new file mode 100644
index 0000000..d8f0616
--- /dev/null
+++ b/ulib/axstd/src/hash/mod.rs
@@ -0,0 +1,3 @@
+pub(crate) mod random;
+
+pub use random::{DefaultHasher, RandomState};
\ No newline at end of file
diff --git a/ulib/axstd/src/hash/random.rs b/ulib/axstd/src/hash/random.rs
new file mode 100644
index 0000000..2735c4c
--- /dev/null
+++ b/ulib/axstd/src/hash/random.rs
@@ -0,0 +1,75 @@
+#![allow(deprecated)]
+use core::hash::{BuildHasher, Hasher, SipHasher13};
+
+use spinlock::SpinNoIrq;
+
+static PARK_MILLER_LEHMER_SEED: SpinNoIrq<u32> = SpinNoIrq::new(0);
+const RAND_MAX: u64 = 2_147_483_647;
+
+pub fn random() -> u128 {
+    let mut seed = PARK_MILLER_LEHMER_SEED.lock();
+    if *seed == 0 {
+        *seed = arceos_api::time::ax_current_time().as_micros() as u32;
+    }
+
+    let mut ret: u128 = 0;
+    for _ in 0..4 {
+        *seed = ((u64::from(*seed) * 48271) % RAND_MAX) as u32;
+        ret = (ret << 32) | (*seed as u128);
+    }
+    ret
+}
+
+pub struct RandomState {
+    k0: u64,
+    k1: u64,
+}
+
+impl RandomState {
+    pub fn new() -> RandomState {
+        let r = random();
+        RandomState {
+            k0: r as u64,
+            k1: (r >> 64) as u64,
+        }
+    }
+}
+
+pub struct DefaultHasher(SipHasher13);
+
+impl BuildHasher for RandomState {
+    type Hasher = DefaultHasher;
+    #[inline]
+    #[allow(deprecated)]
+    fn build_hasher(&self) -> DefaultHasher {
+        DefaultHasher(SipHasher13::new_with_keys(self.k0, self.k1))
+    }
+}
+
+impl Hasher for DefaultHasher {
+    // The underlying `SipHasher13` doesn't override the other
+    // `write_*` methods, so it's ok not to forward them here.
+
+    #[inline]
+    fn write(&mut self, msg: &[u8]) {
+        self.0.write(msg)
+    }
+
+    #[inline]
+    fn write_str(&mut self, s: &str) {
+        self.0.write_str(s);
+    }
+
+    #[inline]
+    fn finish(&self) -> u64 {
+        self.0.finish()
+    }
+}
+
+impl Default for RandomState {
+    /// Constructs a new `RandomState`.
+    #[inline]
+    fn default() -> RandomState {
+        RandomState::new()
+    }
+}
diff --git a/ulib/axstd/src/lib.rs b/ulib/axstd/src/lib.rs
index d256cd5..59de1d3 100644
--- a/ulib/axstd/src/lib.rs
+++ b/ulib/axstd/src/lib.rs
@@ -49,13 +49,27 @@
 #![cfg_attr(all(not(test), not(doc)), no_std)]
 #![feature(doc_cfg)]
 #![feature(doc_auto_cfg)]
+#![allow(internal_features)] // suppress warnings for feature hashmap_internals
+#![feature(hashmap_internals)]
+#![feature(extend_one)]
+#![feature(hasher_prefixfree_extras)]
+#![feature(error_in_core)]
+#![feature(try_reserve_kind)]
+#![feature(thread_local)]
+#![feature(const_hash)]
 
 #[cfg(feature = "alloc")]
 extern crate alloc;
 
 #[cfg(feature = "alloc")]
 #[doc(no_inline)]
-pub use alloc::{boxed, collections, format, string, vec};
+pub use alloc::{boxed, format, string, vec};
+
+#[cfg(feature = "alloc")]
+pub mod collections;
+
+#[cfg(feature = "alloc")]
+pub mod hash;
 
 #[doc(no_inline)]
 pub use core::{arch, cell, cmp, hint, marker, mem, ops, ptr, slice, str};
